\documentclass[oneside]{amsart}
\setlength{\textwidth}{\paperwidth}\addtolength{\textwidth}{-2in}\calclayout
\usepackage{dsfont} 
\usepackage{enumitem}

\DeclareMathOperator{\var}{\mathrm{var}}
\DeclareMathOperator{\cov}{\mathrm{cov}}
\newcommand{\eps}{\epsilon}
\newcommand{\U}{\mathcal{U}}
\newcommand{\Pois}{\mathrm{Poisson}}
\newcommand{\Exp}{\mathrm{Exponential}}
\newcommand{\Bin}{\mathrm{Binomial}}
\newcommand{\Ber}{\mathrm{Bernoulli}}
\newcommand{\Gam}{\mathrm{Gamma}}
\newcommand{\Geom}{\mathrm{Geometric}}
\newcommand{\Z}{\mathds{Z}}
\newcommand{\R}{\mathds{R}}
\newcommand{\N}{\mathds{N}}
\newcommand{\indep}{\perp \!\!\! \perp}

\theoremstyle{definition}
\newtheorem{prob}{Problem}
\renewcommand*{\proofname}{Solution}
\setlist[enumerate]{label={(\roman*)}}

\title{STAT 433: Homework 7}
\author{Daniel Pfeffer}
%------------------------------------------------------------------------------
\begin{document}
\maketitle

\begin{prob}
The planets of the Galactic Empire are distributed in space according to a spatial Poisson process at an approximate density of one planet per cubic parsec. From the Death Star, let $X$ be the distance to the nearest planet.
\end{prob}

\begin{enumerate}[label=(\alph*)]
\item
Find the probability density function of $X$.
\begin{proof}
The event $\{X > r\}$ occurs iff there are no objects in a ball $B_r$ with radius $r$ around the Death State. Note that $B_r$ has Lebesgue measure (volume) $|B_r| = -4 \pi r^3/3$ and 
\[
	P(X > r) = P(N_{B_r} = 0) = P(\Pois(4 \pi r^3/3) = 0) = e^{-4 \pi r^3/3}
\]
Then notice that the cdf is given by
\[
	P(X < r) = 1- e^{-4 \pi r^3/3}.
\]
Differentiating the cdf, we obtain the pdf 
\[
	f(r) = 4 \pi r^2 e^{-4 \pi r^3/3},
\]	
for all $r \geq 0$.
\end{proof}
\item
Find the mean distance from the Death Star to the nearest planet. You can calculate the integral numerically. 
\begin{proof}
The integral of $X$ is
\[
	E X=\int_0^\infty 4 \pi r^3 e^{-4 \pi r^3/3} dr = \frac{1}{36 \sqrt[3]{6 \pi}}\Gamma(1/3) \approx 0.55.
\]
\end{proof}
\end{enumerate}


\begin{prob}
Customers arrive at a bank according to a Poisson process with rate 10 per hour. Given that 5 customers arrived in the first 30 minutes, answer the following questions.
\end{prob}

\begin{enumerate}[label=(\roman*)]
\item
What is the probability that at least 3 arrived in the first 10 minutes?
\begin{proof}
Let $N_{1/2} = 5$ denote the number of arrivals after 30 minutes, let $T_i$ denote the $i$th arrival time, note that 
\[
	(T_1, T_2, T_3, T_4, T_5) \mid N_{1/2} = 5 \sim \U([0, 1/2]).
\]
Then the number of arrivals in the first 10 minutes is $\Bin(5, 1/3)$, and so the event that the at least 3 customers arrived in the first 10 minutes is 
\[
	\binom{5}{3} \frac{1}{3^3} \cdot \frac{2^2}{3^2}
	+ \binom{5}{4} \frac{1}{3^4}  \cdot  \frac{2}{3}
	+  \frac{1}{3^5} 
\]
\end{proof}
\item
What is the probability that 2 arrived in the first 10 minutes and 1 arrived in the next 5 minutes?
\begin{proof}
For a random variable $U_i \sim \U([0,1/2])$, the probability that it lies in the interval $[0,1/6]$ is 1/3, the probability that it lies in the interval $(1/6, 1/4]$ is 1/6, and the probability that it lies in the interval $(1/4, 1/2]$ is 1/2. Then for the 5 i.i.d. random variables $U_1,\dotsc, U_5$, the probability that two of them lie in $[0,1/6]$, 1 lies in $(1/6, 1/4]$, and 2 lie in $(1/4, 1/2]$ is 
\[
	\frac{5!}{2!1!2!} \cdot \frac{1}{3^2}\cdot \frac{1}{6}\cdot\frac{1}{2^2} = \frac{5}{36},
\]
which follows directly from the multinomial distribution. 
\end{proof}
\item
What is the mean of the arriving time for the first customer?
\begin{proof}
Let $T_1$ be the arriving time for the first customer. Then,
\[
	P(T_1 \geq t) = P\left(\min_{1 \leq i \leq 5} U_i\geq t \right) = (1-2t)^5.
\]
for $0 \leq t \leq 1/2$, and the integral of $T_1$ is
\[
	E T_1 = \int_0^{1/2} P(T_1 \geq t) dt 
		= \int_0^{1/2} (1-2t)^2 dt
		= \frac{1}{2} \int_0^1 x^5 dx = \frac{1}{12} \text{ hours}.
\]
So the mean of the arriving time of the first customer is 5 minutes.
\end{proof}

\end{enumerate}

\begin{prob}
Recall the long run car costs problem. Suppose that the lifetime of a car is a random variable with density function $f(t)$. Our methodical Mr. Brown buys a new car as soon as the old one breaks down or reaches $T$ years. Suppose that a new car costs A dollars and that an additional cost of $B$ dollars to repair the vehicle is incurred if it breaks down before time $T$. If $f(t) = \lambda e^{-\lambda t}$, show that for any $A$ and $B$ the optimal time is $T=\infty$. Can you give a simple explanation in words.
\end{prob}


\begin{proof}
The cost of the $i$th cycle is 
\begin{align*}
	E r_i &= A + B  \int_0^T \lambda e^{-\lambda t} dt = A + B (1 - e^{-\lambda T}).
\end{align*}
For the the duration of the $i$th cycle, we have
\[
	E \tau_i = \int_0^T t \lambda e^{-\lambda t}dt  + T \int_T^\infty \lambda e^{-\lambda t}dt 
	= - t e^{-\lambda t} \Big|_0^T + \int_0^T  e^{-\lambda t}dt +  T e^{-\lambda T}
	= \frac{1}{\lambda} (1 - e^{-\lambda T}).
\]
By the elementary renewal theorem tells, the long run reward per unit time is 
\[
	\frac{E r_i}{E \tau_i} = \frac{A \lambda}{1 - e^{-\lambda T}}  + B\lambda.
\]
Since the function is strictly decreasing in $T$, the optimal policy is to set $T = \infty$. This result can be understood intuitively through the memoryless property of exponential random variables: if Mr. Brown used the car for $t$ years, then the probability that it can be used for another $s$ years is the same as the probability for a new car to work for $s$ years. 
\end{proof}

\begin{prob}
A young doctor is working at night in an emergency room. Emergencies come in at times of a Poisson process with rate $\lambda=0.5$ per hour. The doctor can only get to sleep when it has been $c = 36$ minutes (0.6 hours) since the last emergency. For example, if there is an emergency at 1:00 and a second one at 1:17 then she will not be able to get to sleep until at least 1:53, and it will be even later if there is another emergency before that time. We want to compute the long-run fraction of time the doctor spends sleeping with the following strategy.
\end{prob}

\begin{enumerate}[label=(\alph*)]
\item
If $T\sim \Exp(\lambda)$, find $E(T\mid T<c)$.
\begin{proof}
The desired conditional expectation is  
\begin{align*}
	E(T\mid T<c) &= \frac{1}{P(T<c)} \int_0^c t \lambda e^{-\lambda t}dt \\
	&= \frac{1}{1-e^{-\lambda t}}\left( \frac{1}{\lambda} - \frac{1}{\lambda}e^{-\lambda c} - c e^{-\lambda c} \right) \\
	&= \frac{1}{\lambda} - \frac{ce^{-\lambda c}}{1 - e^{-\lambda c}}.
\end{align*}
\end{proof}
\item
Let $J_n= \min\{j:\tau_j > c\}$, where $\tau_1,\tau_2,\dotsc,\tau_n$ are the interarrival times of the Poisson process with rate $\lambda$. Use (a) to show that 
\[
	E(T_{J-1} + c) = \frac{e^{\lambda c} -1}{\lambda} 
\]
\begin{proof}
Use the law of total expectation to write $E T_{J-1} = E E (T_{J-1} \mid J)$. For $J = j$,
\begin{align*}
	E (T_{J-1} \mid J = j) &= E (T_{j-1} \mid J = j) \\
	&= E (\tau_1 + \cdots + \tau_{j-1} \mid \tau_1 < c, \cdots, \tau_{j-1} < c, \tau_j \geq c) \\
	&= \sum_{k=1}^{j-1} E(\tau_k \mid \tau_k < c) \\
	&= (j-1) \left( \frac{1}{\lambda} - \frac{ce^{-\lambda c}}{1 - e^{-\lambda c}} \right)
\end{align*}
So 
\[
	E(T_{J-1} \mid J) = (J-1)  \left( \frac{1}{\lambda} - \frac{ce^{-\lambda c}}{1 - e^{-\lambda c}} \right)
\]
Note that since $J \sim \Geom(e^{-\lambda c})$, $E J = 1/e^{-\lambda c}$. Then 
\begin{align*}
	E T_{J-1} &=  E (J-1)  \left( \frac{1}{\lambda} - \frac{ce^{-\lambda c}}{1 - e^{-\lambda c}} \right) \\
	&= (e^{\lambda c} -1) \left( \frac{1}{\lambda} - \frac{ce^{-\lambda c}}{1 - e^{-\lambda c}} \right) \\
	&= \frac{e^{\lambda c} -1}{\lambda} - c.
\end{align*}
Therefore,  
\[
	E(T_{J-1} + c) = \frac{e^{\lambda c} -1}{\lambda}.
\]
\end{proof}
\item
The doctor alternates between sleeping for an amount of time $s_i$ and being awake for an amount of time $u_i$. Use the result from (b) to compute $E u_i$.
\begin{proof}
We have 
\[
	E u_i = \frac{e^{\lambda c} -1}{\lambda} 
	=\frac{e^{0.5 \cdot 0.6} -1}{0.6} 
	= 2(e^{0.3} - 1).
\]
\end{proof}
\item
Compute the long-run fraction of time the doctor spends sleeping.
\begin{proof}
Since $s_i \sim \Exp(\lambda)$, $E s_i = 1 / \lambda$ and the long-run fraction of time the doctor spends sleeping is 
\[
	\frac{E s_i }{E s_i + E u_i} = \frac{\lambda^{-1}}{\lambda^{-1} + \lambda^{-1} (e^{\lambda c} - 1)}
	= e^{-\lambda c} 
	= e^{-0.3}.
\]
\end{proof}
\item
Model the process using a counter model, and compute (d) in another way using the formula on class.
\begin{proof}
This process can be modeled using a Type II counter model with sleeping corresponding to the alive period and being awake corresponding to the locked period. Then, using the result that the long-run fraction of alive time is 
\[
	\lim_{t\to \infty} p_a(t) = e^{-\lambda Y_i},
\]
and setting $Y_i = c$ for our problem, gives
\[
	\lim_{t\to \infty} p_a(t) = e^{-\lambda c},
\]
the desired result.
\end{proof}
\end{enumerate}






\end{document}
